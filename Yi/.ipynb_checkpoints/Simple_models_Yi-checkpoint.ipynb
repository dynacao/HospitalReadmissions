{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic = pd.read_csv('../../data/diabetic_data_initial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_df = diabetic.replace('?', np.nan)\n",
    "\n",
    "diabetic_df = diabetic_df.sort_values('encounter_id')\n",
    "diabetic_df.drop_duplicates(subset = ['patient_nbr'], keep = 'first', inplace = True)\n",
    "\n",
    "diabetic_df = diabetic_df[~diabetic_df['discharge_disposition_id'].isin([11,13,14,19,20,21])]\n",
    "diabetic_df.drop(diabetic_df.loc[diabetic_df.gender=='Unknown/Invalid'].index, inplace=True)\n",
    "\n",
    "diabetic_df.drop(['encounter_id','patient_nbr','weight','medical_specialty','payer_code'],\\\n",
    "                 axis = 1, inplace = True)\n",
    "\n",
    "diabetic_df['admission_type_id'] = diabetic_df['admission_type_id'].astype('str')\n",
    "diabetic_df['admission_source_id'] = diabetic_df['admission_source_id'].astype('str')\n",
    "diabetic_df['discharge_disposition_id'] = diabetic_df['discharge_disposition_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_df['readmit_30d'] = (diabetic_df['readmitted'] == '<30')\n",
    "\n",
    "# diabetic_df['age_group'] = diabetic_df['age'].replace(\n",
    "#     ['[0-10)','[10-20)','[20-30)','[30-40)','[40-50)','[50-60)','[60-70)','[70-80)','[80-90)','[90-100)'],\n",
    "#     ['inf to adole','inf to adole','adult','adult','mid-age','mid-age','senior','senior','senior','senior'])\n",
    "diabetic_df['age_num'] = diabetic_df['age'].replace(\n",
    "    ['[0-10)','[10-20)','[20-30)','[30-40)','[40-50)','[50-60)','[60-70)','[70-80)','[80-90)','[90-100)'],\n",
    "    [0,10,20,30,40,50,60,70,80,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_df['diag_1'] = diabetic_df['diag_1'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "diabetic_df['diag_2'] = diabetic_df['diag_2'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "diabetic_df['diag_3'] = diabetic_df['diag_3'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "\n",
    "count_1 = diabetic_df['diag_1'].value_counts()\n",
    "index_1 = count_1[count_1>=500].index.tolist()\n",
    "\n",
    "count_2 = diabetic_df['diag_2'].value_counts()\n",
    "index_2 = count_2[count_2>=500].index.tolist()\n",
    "\n",
    "count_3 = diabetic_df['diag_3'].value_counts()\n",
    "index_3 = count_3[count_3>=500].index.tolist()\n",
    "\n",
    "diagnoses = set(index_1 + index_2 + index_3)\n",
    "\n",
    "for d in diagnoses:\n",
    "    diabetic_df[d+'_diag'] = ((diabetic_df['diag_1']==d)|\n",
    "                              (diabetic_df['diag_2']==d)|\n",
    "                              (diabetic_df['diag_3']==d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['metformin','repaglinide','glimepiride','glipizide', 'glyburide','pioglitazone',\n",
    "            'rosiglitazone','insulin']:\n",
    "    diabetic_df[col+'_used'] = np.where(diabetic_df[col]=='No', False, True)\n",
    "# 'nateglinide','glyburide-metformin' (close to 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_df = diabetic_df.drop(['age',\n",
    "                               'diag_1','diag_2','diag_3',\n",
    "                               'metformin','repaglinide','nateglinide','chlorpropamide','glimepiride',\n",
    "                               'acetohexamide','glipizide','glyburide','tolbutamide','pioglitazone',\n",
    "                               'rosiglitazone','acarbose','miglitol','troglitazone','tolazamide','examide',\n",
    "                               'citoglipton','insulin','glyburide-metformin','glipizide-metformin',\n",
    "                               'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone',\n",
    "                               'readmitted'],\n",
    "                               axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 119)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_dum = pd.get_dummies(diabetic_df, drop_first = True)\n",
    "diabetic_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 94)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping variables with <500 minority classes\n",
    "descr = diabetic_dum.describe().T\n",
    "under_500 = descr[descr['mean'] <= (500/len(diabetic_dum))].index.tolist()\n",
    "under_500.remove('race_Asian')\n",
    "diabetic_final = diabetic_dum.drop(under_500, axis = 1)\n",
    "diabetic_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diabetic_final.drop(['readmit_30d'], axis = 1)\n",
    "target = diabetic_final['readmit_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, \n",
    "                                                    target, \n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify = target,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomOverSampler: (101908, 93)\n"
     ]
    }
   ],
   "source": [
    "# RandomOverSampler\n",
    "ros = RandomOverSampler(random_state = 42)\n",
    "X_train, y_train = ros.fit_sample(X_train, y_train)\n",
    "print(f'RandomOverSampler: {X_train.shape}')\n",
    "\n",
    "# # RandomUnderSample\n",
    "# rus = RandomUnderSampler(random_state = 42)\n",
    "# X_train_rus, y_train_rus = rus.fit_sample(X_train, y_train)\n",
    "# print(f'RandomUnderSampler: {X_train_rus.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['number_inpatient','discharge_disposition_id_22','time_in_hospital',\n",
    " 'discharge_disposition_id_3','age_num','num_medications',\n",
    " 'num_lab_procedures','number_diagnoses','discharge_disposition_id_5','num_procedures',\n",
    " '786_diag','434_diag','number_emergency','428_diag','diabetesMed_Yes']\n",
    "X_train_s = X_train[selected]\n",
    "X_test_s = X_test[selected]\n",
    "\n",
    "print(X_train_s.shape)\n",
    "print(X_test_s.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression(random_state = 108)\n",
    "logit.fit(X_train_s, y_train_ros)\n",
    "\n",
    "logit_grid_params = [{\n",
    "    'C': np.linspace(1e-3,0.1,50),\n",
    "    'penalty':['l1','l2'],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'solver': ['liblinear'],\n",
    "    'random_state':[108]\n",
    "}]\n",
    "grid_search_logit = GridSearchCV(logit, logit_grid_params, scoring='roc_auc', cv=5,\n",
    "                                 verbose = 1, n_jobs=-1, )\n",
    "%time grid_search_logit.fit(X_train_s, y_train_ros)\n",
    "\n",
    "print(grid_search_logit.best_params_)\n",
    "print('accuracy:')\n",
    "print(grid_search_logit.best_estimator_.score(X_train_s, y_train_ros))\n",
    "print(grid_search_logit.best_estimator_.score(X_test_s, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_logit.best_estimator_.predict(X_train_s)\n",
    "y_test_pred = grid_search_logit.best_estimator_.predict(X_test_s)\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix(y_train_ros, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train_ros, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC = RandomForestClassifier(oob_score=True, class_weight = 'balanced_subsample', random_state = 108)\n",
    "\n",
    "# RF grid search\n",
    "RF_grid_params = [{\n",
    "    'n_estimators': [500], #range(100,600,100),\n",
    "    'max_depth': [5], #[2,4,6,8],\n",
    "    'max_features': ['sqrt'],\n",
    "    'criterion': ['gini'],\n",
    "    'min_samples_leaf': [50], \n",
    "    'min_samples_split': [250,350], \n",
    "    'class_weight': ['balanced_subsample']\n",
    "}]\n",
    "grid_search_RF = GridSearchCV(RFC, RF_grid_params, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "%time grid_search_RF.fit(X_train_s, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best params\n",
    "print(grid_search_RF.best_params_)\n",
    "grid_search_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy')\n",
    "print(grid_search_RF.best_estimator_.score(X_train_s, y_train_ros))\n",
    "print(grid_search_RF.best_estimator_.score(X_test_s, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_RF.best_estimator_.predict(X_train_s)\n",
    "y_test_pred = grid_search_RF.best_estimator_.predict(X_test_s)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train_ros, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC')\n",
    "print(roc_auc_score(y_train_ros, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RF_fp = pd.DataFrame({'feature':X_train_s.columns,\n",
    "                      'importance':grid_search_RF.best_estimator_.feature_importances_}).\\\n",
    "sort_values('importance',ascending = False)\n",
    "RF_fp.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101766, 50)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic = pd.read_csv('../../data/diabetic_data_initial.csv')\n",
    "diabetic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning\n",
    "diabetic_df = diabetic.replace('?', np.nan)\n",
    "\n",
    "diabetic_df = diabetic_df.sort_values('encounter_id')\n",
    "diabetic_df.drop_duplicates(subset = ['patient_nbr'], keep = 'first', inplace = True)\n",
    "\n",
    "diabetic_df = diabetic_df[~diabetic_df['discharge_disposition_id'].isin([11,13,14,19,20,21])]\n",
    "diabetic_df.drop(diabetic_df.loc[diabetic_df.gender=='Unknown/Invalid'].index, inplace=True)\n",
    "\n",
    "diabetic_df.drop(['encounter_id','patient_nbr','weight','medical_specialty','payer_code'],\\\n",
    "                 axis = 1, inplace = True)\n",
    "\n",
    "diabetic_df['admission_type_id'] = diabetic_df['admission_type_id'].astype('str')\n",
    "diabetic_df['admission_source_id'] = diabetic_df['admission_source_id'].astype('str')\n",
    "diabetic_df['discharge_disposition_id'] = diabetic_df['discharge_disposition_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 45)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "diabetic_df['readmit_30d'] = (diabetic_df['readmitted'] == '<30')\n",
    "\n",
    "diabetic_df['age_num'] = diabetic_df['age'].replace(\n",
    "    ['[0-10)','[10-20)','[20-30)','[30-40)','[40-50)','[50-60)','[60-70)','[70-80)','[80-90)','[90-100)'],\n",
    "    [0,10,20,30,40,50,60,70,80,90])\n",
    "\n",
    "diabetic_df['diag_1'] = diabetic_df['diag_1'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "diabetic_df['diag_2'] = diabetic_df['diag_2'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "diabetic_df['diag_3'] = diabetic_df['diag_3'].str.split('.', expand = True).drop(1, axis = 1)\n",
    "count_1 = diabetic_df['diag_1'].value_counts()\n",
    "index_1 = count_1[count_1>=500].index.tolist()\n",
    "count_2 = diabetic_df['diag_2'].value_counts()\n",
    "index_2 = count_2[count_2>=500].index.tolist()\n",
    "count_3 = diabetic_df['diag_3'].value_counts()\n",
    "index_3 = count_3[count_3>=500].index.tolist()\n",
    "diagnoses = set(index_1 + index_2 + index_3)\n",
    "for d in diagnoses:\n",
    "    diabetic_df[d+'_diag'] = ((diabetic_df['diag_1']==d)|\n",
    "                              (diabetic_df['diag_2']==d)|\n",
    "                              (diabetic_df['diag_3']==d))\n",
    "    \n",
    "for col in ['metformin','repaglinide','glimepiride','glipizide', 'glyburide','pioglitazone',\n",
    "            'rosiglitazone','insulin']:\n",
    "    diabetic_df[col+'_used'] = np.where(diabetic_df[col]=='No', False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetic_df = diabetic_df.drop(['age',\n",
    "                                'diag_1','diag_2','diag_3',\n",
    "                                'metformin','repaglinide','nateglinide','chlorpropamide','glimepiride',\n",
    "                                'acetohexamide','glipizide','glyburide','tolbutamide','pioglitazone',\n",
    "                                'rosiglitazone','acarbose','miglitol','troglitazone','tolazamide','examide',\n",
    "                                'citoglipton','insulin','glyburide-metformin','glipizide-metformin',\n",
    "                                'glimepiride-pioglitazone','metformin-rosiglitazone','metformin-pioglitazone',\n",
    "                                'readmitted'],\n",
    "                                 axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 119)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetic_dum = pd.get_dummies(diabetic_df, drop_first = True)\n",
    "diabetic_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69970, 94)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping variables with <500 minority classes\n",
    "descr = diabetic_dum.describe().T\n",
    "under_500 = descr[descr['mean'] <= (500/len(diabetic_dum))].index.tolist()\n",
    "under_500.remove('race_Asian')\n",
    "diabetic_final = diabetic_dum.drop(under_500, axis = 1)\n",
    "diabetic_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = diabetic_final.drop(['readmit_30d'], axis = 1)\n",
    "target = diabetic_final['readmit_30d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2,stratify = target,\n",
    "                                                    random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "checking VIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# X_vif = pd.DataFrame(X_train, dtype=float)\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "# vif_data = pd.DataFrame() \n",
    "# vif_data[\"feature\"] = X_vif.columns\n",
    "# vif_data[\"VIF\"] = [variance_inflation_factor(X_vif.values, i) \n",
    "#                           for i in range(len(X_vif.columns))] \n",
    "# print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression with no regularization or CV (93 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10000000.0, class_weight='balanced', random_state=42,\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(C = 1e7, solver='liblinear', random_state = 42, class_weight = 'balanced')\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.6613727311705017\n",
      "0.6632842646848649\n",
      "------------------------------------------------------------\n",
      "confusion matrix:\n",
      "[[34227 16727]\n",
      " [ 2228  2794]]\n",
      "[[8620 4119]\n",
      " [ 593  662]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC:\n",
      "0.6140377831516285\n",
      "0.602076129112563\n"
     ]
    }
   ],
   "source": [
    "print('accuracy:')\n",
    "print(logit.score(X_train, y_train))\n",
    "print(logit.score(X_test, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = logit.predict(X_train)\n",
    "y_test_pred = logit.predict(X_test)\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression with no regularization or CV (top 43 features from previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_coefs = pd.DataFrame({'features': X_train.columns,\n",
    "                            'coef': logit.coef_[0]})\n",
    "logit_coefs['abs_coef'] = np.abs(logit_coefs['coef'])\n",
    "logit_43 = logit_coefs.sort_values('abs_coef', ascending = False).iloc[:,0:2].head(43).features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_43 = X_train[logit_43]\n",
    "X_test_43 = X_test[logit_43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:\n",
      "0.6620515935400886\n",
      "0.6642132342432471\n",
      "------------------------------------------------------------\n",
      "confusion matrix:\n",
      "[[34359 16595]\n",
      " [ 2322  2700]]\n",
      "[[8647 4092]\n",
      " [ 607  648]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC:\n",
      "0.6059742479090354\n",
      "0.5975581776825504\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(C = 1e7, solver='liblinear', random_state = 42, class_weight = 'balanced')\n",
    "logit.fit(X_train_43, y_train)\n",
    "\n",
    "print('accuracy:')\n",
    "print(logit.score(X_train_43, y_train))\n",
    "print(logit.score(X_test_43, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = logit.predict(X_train_43)\n",
    "y_test_pred = logit.predict(X_test_43)\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>discharge_disposition_id_22</td>\n",
       "      <td>1.519637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discharge_disposition_id_5</td>\n",
       "      <td>1.251283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discharge_disposition_id_2</td>\n",
       "      <td>0.719786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discharge_disposition_id_3</td>\n",
       "      <td>0.683762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>722_diag</td>\n",
       "      <td>-0.619348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>discharge_disposition_id_4</td>\n",
       "      <td>0.577370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>discharge_disposition_id_18</td>\n",
       "      <td>0.543966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>786_diag</td>\n",
       "      <td>-0.475954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>403_diag</td>\n",
       "      <td>0.441048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>440_diag</td>\n",
       "      <td>0.426389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>278_diag</td>\n",
       "      <td>-0.372828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>number_inpatient</td>\n",
       "      <td>0.352661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>272_diag</td>\n",
       "      <td>-0.349798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>admission_source_id_5</td>\n",
       "      <td>-0.335512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>discharge_disposition_id_6</td>\n",
       "      <td>0.318430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features      coef\n",
       "0   discharge_disposition_id_22  1.519637\n",
       "1    discharge_disposition_id_5  1.251283\n",
       "2    discharge_disposition_id_2  0.719786\n",
       "4    discharge_disposition_id_3  0.683762\n",
       "3                      722_diag -0.619348\n",
       "6    discharge_disposition_id_4  0.577370\n",
       "5   discharge_disposition_id_18  0.543966\n",
       "8                      786_diag -0.475954\n",
       "10                     403_diag  0.441048\n",
       "9                      440_diag  0.426389\n",
       "16                     278_diag -0.372828\n",
       "12             number_inpatient  0.352661\n",
       "17                     272_diag -0.349798\n",
       "7         admission_source_id_5 -0.335512\n",
       "25   discharge_disposition_id_6  0.318430"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_coefs = pd.DataFrame({'features': X_train_43.columns,\n",
    "                            'coef': logit.coef_[0]})\n",
    "logit_coefs['abs_coef'] = np.abs(logit_coefs['coef'])\n",
    "logit_coefs.sort_values('abs_coef', ascending = False).iloc[:,0:2].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression with regularization and CV (93 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.6min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:  3.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 50s\n",
      "LogisticRegression(C=0.011183673469387756, class_weight='balanced',\n",
      "                   max_iter=1000, penalty='l1', random_state=42,\n",
      "                   solver='liblinear')\n",
      "------------------------------------------------------------\n",
      "accuracy:\n",
      "0.6642132342432471\n",
      "0.6654994997856224\n",
      "------------------------------------------------------------\n",
      "confusion matrix:\n",
      "[[34428 16526]\n",
      " [ 2270  2752]]\n",
      "[[8636 4103]\n",
      " [ 578  677]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC:\n",
      "0.6118285494290249\n",
      "0.6086802175081758\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(max_iter = 1000, class_weight = 'balanced', random_state = 42)\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "logit_grid_params = [{'C': np.linspace(1e-3,0.5,50),'penalty':['l1','l2'],\n",
    "                      'class_weight':[None,'balanced'],'solver': ['liblinear']}]\n",
    "grid_search_logit = GridSearchCV(logit, logit_grid_params, scoring='roc_auc', cv=5, verbose = 1, n_jobs=-1)\n",
    "%time grid_search_logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(grid_search_logit.best_estimator_)\n",
    "print('--'*30)\n",
    "print('accuracy:')\n",
    "print(grid_search_logit.best_estimator_.score(X_train_scaled, y_train))\n",
    "print(grid_search_logit.best_estimator_.score(X_test_scaled, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_logit.best_estimator_.predict(X_train_scaled)\n",
    "y_test_pred = grid_search_logit.best_estimator_.predict(X_test_scaled)\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression with regularization and CV (top 43 features from previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "logit_cv_coefs = pd.DataFrame({'features': X_train.columns,'coef': grid_search_logit.best_estimator_.coef_[0]})\n",
    "logit_cv_coefs['abs_coef'] = np.abs(logit_cv_coefs['coef'])\n",
    "logit_cv_43 = logit_cv_coefs.sort_values('abs_coef', ascending = False).iloc[:,0:2].head(43).features.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_43 = X_train[logit_cv_43]\n",
    "X_test_43 = X_test[logit_cv_43]\n",
    "\n",
    "# # standardization\n",
    "# scaler = StandardScaler().fit(X_train_43)\n",
    "# X_train_scaled = scaler.transform(X_train_43)\n",
    "# X_test_scaled = scaler.transform(X_test_43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   30.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 35.5 s\n",
      "LogisticRegression(C=0.0009061224489795917, class_weight='balanced',\n",
      "                   max_iter=1000, random_state=42, solver='liblinear')\n",
      "------------------------------------------------------------\n",
      "accuracy:\n",
      "0.6574246105473774\n",
      "0.6576389881377733\n",
      "------------------------------------------------------------\n",
      "confusion matrix:\n",
      "[[34016 16938]\n",
      " [ 2238  2784]]\n",
      "[[8532 4207]\n",
      " [ 584  671]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC:\n",
      "0.6109716689202044\n",
      "0.6022078262036241\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(max_iter = 1000, class_weight = 'balanced', random_state = 42)\n",
    "logit.fit(X_train_scaled, y_train)\n",
    "\n",
    "logit_grid_params = [{'C': np.linspace(1e-4,0.1,50),'penalty':['l1','l2'],\n",
    "                      'class_weight':['balanced'],'solver': ['liblinear']}]\n",
    "grid_search_logit = GridSearchCV(logit, logit_grid_params, scoring='roc_auc', cv=5, verbose = 1, n_jobs=-1)\n",
    "%time grid_search_logit.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_logit.best_estimator_)\n",
    "print('--'*30)\n",
    "print('accuracy:')\n",
    "print(grid_search_logit.best_estimator_.score(X_train, y_train))\n",
    "print(grid_search_logit.best_estimator_.score(X_test, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_logit.best_estimator_.predict(X_train)\n",
    "y_test_pred = grid_search_logit.best_estimator_.predict(X_test)\n",
    "print('confusion matrix:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>number_inpatient</td>\n",
       "      <td>0.181850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>discharge_disposition_id_22</td>\n",
       "      <td>0.174372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discharge_disposition_id_3</td>\n",
       "      <td>0.154015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>discharge_disposition_id_5</td>\n",
       "      <td>0.113616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diabetesMed_Yes</td>\n",
       "      <td>0.084625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>discharge_disposition_id_2</td>\n",
       "      <td>0.083586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>786_diag</td>\n",
       "      <td>-0.077248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>discharge_disposition_id_18</td>\n",
       "      <td>0.073580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>403_diag</td>\n",
       "      <td>0.072752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>number_emergency</td>\n",
       "      <td>0.069256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>age_num</td>\n",
       "      <td>0.064537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>number_diagnoses</td>\n",
       "      <td>0.063117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>time_in_hospital</td>\n",
       "      <td>0.057973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>discharge_disposition_id_6</td>\n",
       "      <td>0.054139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>434_diag</td>\n",
       "      <td>0.051895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       features      coef\n",
       "0              number_inpatient  0.181850\n",
       "1   discharge_disposition_id_22  0.174372\n",
       "2    discharge_disposition_id_3  0.154015\n",
       "3    discharge_disposition_id_5  0.113616\n",
       "5               diabetesMed_Yes  0.084625\n",
       "4    discharge_disposition_id_2  0.083586\n",
       "7                      786_diag -0.077248\n",
       "6   discharge_disposition_id_18  0.073580\n",
       "8                      403_diag  0.072752\n",
       "9              number_emergency  0.069256\n",
       "12                      age_num  0.064537\n",
       "11             number_diagnoses  0.063117\n",
       "13             time_in_hospital  0.057973\n",
       "10   discharge_disposition_id_6  0.054139\n",
       "15                     434_diag  0.051895"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_cv_coefs = pd.DataFrame({'features': X_train_43.columns,'coef': grid_search_logit.best_estimator_.coef_[0]})\n",
    "logit_cv_coefs['abs_coef'] = np.abs(logit_cv_coefs['coef'])\n",
    "logit_cv_coefs.sort_values('abs_coef', ascending = False).iloc[:,0:2].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest with CV (93 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RF = RandomForestClassifier(oob_score=True, class_weight = 'balanced_subsample', random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=6,\n",
      "                       min_samples_leaf=50, min_samples_split=300,\n",
      "                       n_estimators=600, oob_score=True, random_state=42)\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.6506002572531084\n",
      "0.6489924253251393\n",
      "------------------------------------------------------------\n",
      "confusion matrix\n",
      "[[33551 17403]\n",
      " [ 2155  2867]]\n",
      "[[8380 4359]\n",
      " [ 553  702]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC\n",
      "0.6146723697827139\n",
      "0.6085924924213969\n"
     ]
    }
   ],
   "source": [
    "RF_grid_params = [{\n",
    "    'n_estimators': [600], #range(100,800,100),\n",
    "    'max_depth': [6], #[4,5,6],\n",
    "    'max_features': ['sqrt'], #['sqrt','log2'],\n",
    "    'criterion': ['gini'], #['gini','entropy'],\n",
    "    'min_samples_leaf': [50], #[40,50,60],\n",
    "    'min_samples_split': [300], #range(200,400,50),\n",
    "    'class_weight': ['balanced_subsample'],\n",
    "    'random_state': [42]}]\n",
    "grid_search_RF = GridSearchCV(RF, RF_grid_params, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "%time grid_search_RF.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_RF.best_estimator_)\n",
    "print('--'*30)\n",
    "print('accuracy')\n",
    "print(grid_search_RF.best_estimator_.score(X_train, y_train))\n",
    "print(grid_search_RF.best_estimator_.score(X_test, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_RF.best_estimator_.predict(X_train)\n",
    "y_test_pred = grid_search_RF.best_estimator_.predict(X_test)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest with CV (top 43 features from previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_coefs = pd.DataFrame({'feature':X_train.columns,\n",
    "                      'importance':grid_search_RF.best_estimator_.feature_importances_})\n",
    "RF_43 = RF_coefs.sort_values('importance',ascending = False).head(43).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_43 = X_train[RF_43]\n",
    "X_test_43 = X_test[RF_43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 7s\n",
      "RandomForestClassifier(class_weight='balanced_subsample', max_depth=6,\n",
      "                       max_features='sqrt', min_samples_leaf=50,\n",
      "                       min_samples_split=250, n_estimators=300, oob_score=True,\n",
      "                       random_state=42)\n",
      "------------------------------------------------------------\n",
      "accuracy\n",
      "0.6550843218522224\n",
      "0.6547091610690295\n",
      "------------------------------------------------------------\n",
      "confusion matrix\n",
      "[[33858 17096]\n",
      " [ 2211  2811]]\n",
      "[[8478 4261]\n",
      " [ 571  684]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC\n",
      "0.612109422939115\n",
      "0.6052676334461198\n"
     ]
    }
   ],
   "source": [
    "RF_grid_params = [{\n",
    "    'n_estimators': [300], #range(100,800,100),\n",
    "    'max_depth': [6], #[4,5,6],\n",
    "    'max_features': ['sqrt'], #['sqrt','log2'],\n",
    "    'criterion': ['gini'], #['gini','entropy'],\n",
    "    'min_samples_leaf': [50], #[40,50,60],\n",
    "    'min_samples_split': [250], #range(200,400,50),\n",
    "    'class_weight': ['balanced_subsample'],\n",
    "    'random_state': [42]}]\n",
    "grid_search_RF = GridSearchCV(RF, RF_grid_params, scoring='roc_auc', cv=5, n_jobs=-1)\n",
    "%time grid_search_RF.fit(X_train_43, y_train)\n",
    "\n",
    "print(grid_search_RF.best_estimator_)\n",
    "print('--'*30)\n",
    "print('accuracy')\n",
    "print(grid_search_RF.best_estimator_.score(X_train_43, y_train))\n",
    "print(grid_search_RF.best_estimator_.score(X_test_43, y_test))\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_RF.best_estimator_.predict(X_train_43)\n",
    "y_test_pred = grid_search_RF.best_estimator_.predict(X_test_43)\n",
    "print('confusion matrix')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_coefs = pd.DataFrame({'feature':X_train_43.columns,\n",
    "                         'importance':grid_search_RF.best_estimator_.feature_importances_})\n",
    "RF_coefs.sort_values('importance',ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting with CV (93 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101908, 93)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     50954\n",
       "False    50954\n",
       "Name: readmit_30d, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# resampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state = 42)\n",
    "X_train, y_train = ros.fit_sample(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "GB = GradientBoostingClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:  1.8min remaining:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min\n",
      "GradientBoostingClassifier(learning_rate=1, max_depth=4, min_samples_leaf=50,\n",
      "                           min_samples_split=300, n_estimators=300,\n",
      "                           random_state=42, subsample=0.8)\n",
      "------------------------------------------------------------\n",
      "accuracy:\n",
      "0.8317011422066962\n",
      "0.723024153208518\n",
      "confusion matrices:\n",
      "[[40894 10060]\n",
      " [ 7091 43863]]\n",
      "[[9680 3059]\n",
      " [ 817  438]]\n",
      "------------------------------------------------------------\n",
      "AUC-ROC:\n",
      "0.8317011422066962\n",
      "0.5544376227721189\n"
     ]
    }
   ],
   "source": [
    "GB_grid_params = [{\n",
    "    'learning_rate': [1], #[0.8,0,9,1.0,1.1,1.2],\n",
    "    'n_estimators': [300], #range(100,800,100),\n",
    "    'max_depth': [4],\n",
    "    'subsample': [0.8], #np.linspace(0.6,0.9,10),\n",
    "#     'max_features':['sqrt','log2'],\n",
    "#     'criterion': ['mse','friedman_mse','mae'],\n",
    "    'min_samples_leaf': [50], #range(50,80,5),\n",
    "    'min_samples_split': [300], #[400,500,600,700,800],\n",
    "    'random_state':[42]\n",
    "}]\n",
    "grid_search_GB = GridSearchCV(GB, GB_grid_params, scoring='roc_auc', cv=5, verbose = 1, n_jobs=-1)\n",
    "%time grid_search_GB.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search_GB.best_estimator_)\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_GB.best_estimator_.predict(X_train)\n",
    "y_test_pred = grid_search_GB.best_estimator_.predict(X_test)\n",
    "print('accuracy:')\n",
    "print(grid_search_GB.best_estimator_.score(X_train, y_train))\n",
    "print(grid_search_GB.best_estimator_.score(X_test, y_test))\n",
    "print('confusion matrices:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradient boosting with CV (top 43 features from previous model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_coefs = pd.DataFrame({'feature':X_train.columns,\n",
    "                      'importance':grid_search_GB.best_estimator_.feature_importances_})\n",
    "GB_43 = RF_coefs.sort_values('importance',ascending = False).head(43).feature.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_43 = X_train[GB_43]\n",
    "X_test_43 = X_test[GB_43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_grid_params = [{\n",
    "#     'learning_rate': [0.8,0,9,1.0,1.1,1.2],\n",
    "    'n_estimators': [600], #range(100,800,100),\n",
    "    'max_depth': [6],\n",
    "    'subsample': [0.8], #np.linspace(0.6,0.9,10),\n",
    "    'max_features':['sqrt'],\n",
    "#     'criterion': ['mse','friedman_mse','mae'],\n",
    "    'min_samples_leaf': [50], #range(50,80,5),\n",
    "    'min_samples_split': [500], #[400,500,600,700,800],\n",
    "    'random_state':[42]\n",
    "}]\n",
    "grid_search_GB = GridSearchCV(GB, GB_grid_params, scoring='roc_auc', cv=5, verbose = 1, n_jobs=-1)\n",
    "%time grid_search_GB.fit(X_train_43, y_train)\n",
    "\n",
    "print(grid_search_GB.best_estimator_)\n",
    "print('--'*30)\n",
    "y_train_pred = grid_search_GB.best_estimator_.predict(X_train_43)\n",
    "y_test_pred = grid_search_GB.best_estimator_.predict(X_test_43)\n",
    "print('accuracy:')\n",
    "print(grid_search_GB.best_estimator_.score(X_train_43, y_train))\n",
    "print(grid_search_GB.best_estimator_.score(X_test_43, y_test))\n",
    "print('confusion matrices:')\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print('--'*30)\n",
    "print('AUC-ROC:')\n",
    "print(roc_auc_score(y_train, y_train_pred))\n",
    "print(roc_auc_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_coefs = pd.DataFrame({'feature':X_train.columns,\n",
    "                      'importance':grid_search_GB.best_estimator_.feature_importances_})\n",
    "GB_coef.sort_values('importance', ascending = False).head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
